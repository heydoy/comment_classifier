{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "comment_classifier.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MBp6fXj_xfQ"
      },
      "source": [
        "# 1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xxXj8xH_xfT"
      },
      "source": [
        "try:\n",
        "  # Colab only\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv4Y8nlJ_xfU",
        "outputId": "0abe650c-7cc0-4d84-8efd-289595717e01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 64.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeomYCGm_xfU",
        "outputId": "740bad3d-4c1b-442e-d208-912e1b2f6d36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKemDJGo_xfV",
        "outputId": "a019429a-58fb-4ee0-fea3-e5e4f85e9ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#colab에서 실행 중이라면...\n",
        "!git clone https://github.com/hukim1112/comment_classifier.git\n",
        "import os\n",
        "os.chdir('/content/comment_classifier')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'comment_classifier'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 74 (delta 0), reused 1 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPERT5Gr_xfV",
        "outputId": "94abef0f-d7ee-4133-ebcd-0c733b4d2322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from konlpy.tag import Twitter\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "keras = tf.keras\n",
        "t = Twitter()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOFEGleuAX6J",
        "outputId": "33a599f3-24ef-4da2-c7c5-3e1041846fd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t.morphs(\"나는 배고프다\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['나', '는', '배고프다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzZLNnee_xfW"
      },
      "source": [
        "# 2. fit tokenizer to our datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyCGQiB__xfW"
      },
      "source": [
        "from vectorizer import BaseVectorizer\n",
        "tokenizer = BaseVectorizer(t.morphs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqmKrRdq_xfW"
      },
      "source": [
        "df = pd.read_csv('train_intent.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5rmKH30_xfX",
        "outputId": "fd07d41e-e57b-49f3-eca2-f7bfa6372a93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3591"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqc4IbD6_xfX",
        "outputId": "b2849b52-cceb-468a-84be-64febca21440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.fit(df['question'].values)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scanning was done                                        \n",
            "1405 terms are recognized\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<vectorizer.BaseVectorizer at 0x7fab9f851bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-BMsccA_xfX",
        "outputId": "bfc2ee24-a303-4696-f0a1-e9c1622ca0a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.vocabulary_"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_PAD_': 0,\n",
              " '_UNK_': 1,\n",
              " '_STA_': 2,\n",
              " '_EOS_': 3,\n",
              " '오늘': 4,\n",
              " '알려줘': 5,\n",
              " '명언': 6,\n",
              " '이': 7,\n",
              " '누구': 8,\n",
              " '알려줘요': 9,\n",
              " '날씨': 10,\n",
              " '주': 11,\n",
              " '지금': 12,\n",
              " '해줘': 13,\n",
              " '시간': 14,\n",
              " '뭐': 15,\n",
              " '노래': 16,\n",
              " '추천': 17,\n",
              " '상태': 18,\n",
              " '들려줘': 19,\n",
              " '몇': 20,\n",
              " '말': 21,\n",
              " '공기': 22,\n",
              " '이슈': 23,\n",
              " '요': 24,\n",
              " '무슨': 25,\n",
              " '좀': 26,\n",
              " '이번': 27,\n",
              " '맛집': 28,\n",
              " '요즘': 29,\n",
              " '나': 30,\n",
              " '알려줄래': 31,\n",
              " '주변': 32,\n",
              " '내일': 33,\n",
              " '해줘요': 34,\n",
              " '알려주라': 35,\n",
              " '지': 36,\n",
              " '며칠': 37,\n",
              " '알려줄래요': 38,\n",
              " '의': 39,\n",
              " '좋은': 40,\n",
              " '뉴스': 41,\n",
              " '사건': 42,\n",
              " '현재': 43,\n",
              " '이제': 44,\n",
              " '곧': 45,\n",
              " '번역': 46,\n",
              " '날짜': 47,\n",
              " '에요': 48,\n",
              " '에게': 49,\n",
              " '되는': 50,\n",
              " '인가요': 51,\n",
              " '뭔': 52,\n",
              " '거': 53,\n",
              " '핫': 54,\n",
              " '미세먼지': 55,\n",
              " '하나': 56,\n",
              " '시야': 57,\n",
              " '니': 58,\n",
              " '가장': 59,\n",
              " '화제': 60,\n",
              " '어디': 61,\n",
              " '중국어': 62,\n",
              " '있나요': 63,\n",
              " '이야': 64,\n",
              " '요일': 65,\n",
              " '인지': 66,\n",
              " '힘': 67,\n",
              " '들려줘요': 68,\n",
              " '일': 69,\n",
              " '에': 70,\n",
              " '마스크': 71,\n",
              " '어떻게': 72,\n",
              " '우산': 73,\n",
              " '해주라': 74,\n",
              " '가': 75,\n",
              " '해주세요': 76,\n",
              " '멋진': 77,\n",
              " '결과': 78,\n",
              " '바람': 79,\n",
              " '프랑스어': 80,\n",
              " '다음': 81,\n",
              " '있니': 82,\n",
              " '전': 83,\n",
              " '누군지': 84,\n",
              " '알려주세요': 85,\n",
              " '라': 86,\n",
              " '영어': 87,\n",
              " '음악': 88,\n",
              " '시': 89,\n",
              " '치킨': 90,\n",
              " '최근': 91,\n",
              " '분': 92,\n",
              " '수': 93,\n",
              " '해줄래': 94,\n",
              " '해줄래요': 95,\n",
              " '만': 96,\n",
              " '어때': 97,\n",
              " '비': 98,\n",
              " '음식': 99,\n",
              " '들려주라': 100,\n",
              " '야': 101,\n",
              " '아니': 102,\n",
              " '음식점': 103,\n",
              " '해': 104,\n",
              " '한': 105,\n",
              " '게': 106,\n",
              " '궁금해': 107,\n",
              " '해주': 108,\n",
              " '어때요': 109,\n",
              " '맛있는': 110,\n",
              " '알려줄': 111,\n",
              " '일본어': 112,\n",
              " '모레': 113,\n",
              " '있던': 114,\n",
              " '했던': 115,\n",
              " '유행': 116,\n",
              " '하는게': 117,\n",
              " '뜨는게': 118,\n",
              " '일이': 119,\n",
              " '어떤': 120,\n",
              " '부산': 121,\n",
              " '주요': 122,\n",
              " '많이': 123,\n",
              " '적': 124,\n",
              " '들려주세요': 125,\n",
              " '한테': 126,\n",
              " '죠': 127,\n",
              " '대구': 128,\n",
              " '되니': 129,\n",
              " '는': 130,\n",
              " '써야': 131,\n",
              " '눈': 132,\n",
              " '부니': 133,\n",
              " '들을래': 134,\n",
              " '전주': 135,\n",
              " '그': 136,\n",
              " '좋니': 137,\n",
              " '스페인어': 138,\n",
              " '신지': 139,\n",
              " '날': 140,\n",
              " '어떠니': 141,\n",
              " '12일': 142,\n",
              " '인': 143,\n",
              " '알려줄수': 144,\n",
              " '듣고': 145,\n",
              " '로': 146,\n",
              " '집': 147,\n",
              " '신문': 148,\n",
              " '어제': 149,\n",
              " '해봐': 150,\n",
              " '대전': 151,\n",
              " '서울': 152,\n",
              " '제': 153,\n",
              " '야구': 154,\n",
              " '날인': 155,\n",
              " '시지': 156,\n",
              " '오나요': 157,\n",
              " '아산': 158,\n",
              " '틀어줘': 159,\n",
              " '들려줄래': 160,\n",
              " '행복한': 161,\n",
              " '최신': 162,\n",
              " '단어': 163,\n",
              " '이지': 164,\n",
              " '이에요': 165,\n",
              " '먼지': 166,\n",
              " '있어': 167,\n",
              " '울산': 168,\n",
              " '제일': 169,\n",
              " '라틴어': 170,\n",
              " '기사': 171,\n",
              " '도': 172,\n",
              " '광명': 173,\n",
              " '들을래요': 174,\n",
              " '나온': 175,\n",
              " '얘기': 176,\n",
              " '조언': 177,\n",
              " '있어요': 178,\n",
              " '궁금해요': 179,\n",
              " '사회': 180,\n",
              " '했던것': 181,\n",
              " '뜨는': 182,\n",
              " '됐던': 183,\n",
              " '먹을': 184,\n",
              " '에픽하이': 185,\n",
              " '에서': 186,\n",
              " '정치': 187,\n",
              " '저번': 188,\n",
              " '아시나요': 189,\n",
              " '하늘': 190,\n",
              " '맑니': 191,\n",
              " '윤하': 192,\n",
              " '들려주겠나요': 193,\n",
              " '저': 194,\n",
              " '일까': 195,\n",
              " '다음주': 196,\n",
              " '누굴까': 197,\n",
              " '요슴': 198,\n",
              " '맛': 199,\n",
              " '아': 200,\n",
              " '알아요': 201,\n",
              " '농구': 202,\n",
              " '할까': 203,\n",
              " '하니': 204,\n",
              " '를': 205,\n",
              " '알려': 206,\n",
              " '모르겠어': 207,\n",
              " '4월': 208,\n",
              " '토요일': 209,\n",
              " '난': 210,\n",
              " '신나는': 211,\n",
              " '알': 212,\n",
              " '이탈리아어': 213,\n",
              " '니요': 214,\n",
              " '행복해지는': 215,\n",
              " '9월': 216,\n",
              " '인천': 217,\n",
              " '좋나요': 218,\n",
              " '오니': 219,\n",
              " '주제가': 220,\n",
              " '가요': 221,\n",
              " '문장': 222,\n",
              " '일본말': 223,\n",
              " '축구': 224,\n",
              " '이니': 225,\n",
              " '줘': 226,\n",
              " '맑은': 227,\n",
              " '경주': 228,\n",
              " '대통령': 229,\n",
              " '부나요': 230,\n",
              " '맛있니': 231,\n",
              " '은': 232,\n",
              " '재생': 233,\n",
              " '래': 234,\n",
              " '데': 235,\n",
              " '올림픽': 236,\n",
              " '있냐': 237,\n",
              " '좋아': 238,\n",
              " '어떤지': 239,\n",
              " '논산': 240,\n",
              " '3월': 241,\n",
              " '15일': 242,\n",
              " '포항': 243,\n",
              " '써야하나요': 244,\n",
              " '광주': 245,\n",
              " '구름': 246,\n",
              " '마포구': 247,\n",
              " '고기': 248,\n",
              " '피자': 249,\n",
              " '천안': 250,\n",
              " '들': 251,\n",
              " '정준영': 252,\n",
              " '합니다': 253,\n",
              " '단독': 254,\n",
              " '였는지': 255,\n",
              " '쓰는': 256,\n",
              " '달': 257,\n",
              " '돼요': 258,\n",
              " '해줄수': 259,\n",
              " '라고': 260,\n",
              " '누군데': 261,\n",
              " '있었니': 262,\n",
              " '있었나요': 263,\n",
              " '맑은가요': 264,\n",
              " '맛있어': 265,\n",
              " '먹을지': 266,\n",
              " '들려주겠니': 267,\n",
              " '좋던데': 268,\n",
              " '싶네': 269,\n",
              " '미국': 270,\n",
              " '사랑': 271,\n",
              " '독일어': 272,\n",
              " '그리스어': 273,\n",
              " '심심하거든': 274,\n",
              " '해줄': 275,\n",
              " '너': 276,\n",
              " '들려줘야': 277,\n",
              " '저기': 278,\n",
              " '혹시': 279,\n",
              " '번만': 280,\n",
              " '부탁': 281,\n",
              " '어떨까': 282,\n",
              " '쓸까': 283,\n",
              " '구로구': 284,\n",
              " '군산': 285,\n",
              " '오는지': 286,\n",
              " '우비': 287,\n",
              " '입을까': 288,\n",
              " '충주': 289,\n",
              " '있죠': 290,\n",
              " '뽀로로': 291,\n",
              " '와이': 292,\n",
              " '틀어주라': 293,\n",
              " '슬픈': 294,\n",
              " '싶어요': 295,\n",
              " 'ost': 296,\n",
              " '틀어': 297,\n",
              " '줬으면': 298,\n",
              " '오': 299,\n",
              " '차트': 300,\n",
              " '밤': 301,\n",
              " '해요': 302,\n",
              " '제라드': 303,\n",
              " '까먹었어': 304,\n",
              " '속초': 305,\n",
              " '있겠니': 306,\n",
              " '좋아요': 307,\n",
              " '제주': 308,\n",
              " '냐': 309,\n",
              " '와': 310,\n",
              " '맑나요': 311,\n",
              " '꼈나요': 312,\n",
              " '올까': 313,\n",
              " '흐리니': 314,\n",
              " '돼': 315,\n",
              " '들려줄수': 316,\n",
              " '목소리': 317,\n",
              " '기쁜': 318,\n",
              " '힙합': 319,\n",
              " '오빠': 320,\n",
              " '방탄': 321,\n",
              " '인기': 322,\n",
              " '줄': 323,\n",
              " '들려줄래요': 324,\n",
              " '냉장고': 325,\n",
              " '학교': 326,\n",
              " '사람': 327,\n",
              " '양양': 328,\n",
              " '보여': 329,\n",
              " '쓰는게': 330,\n",
              " '오산': 331,\n",
              " '있을까요': 332,\n",
              " '줘요': 333,\n",
              " '박': 334,\n",
              " '정몽주': 335,\n",
              " '진천': 336,\n",
              " '산천': 337,\n",
              " '동두천': 338,\n",
              " '김치': 339,\n",
              " '라면': 340,\n",
              " '떡갈비': 341,\n",
              " '갈비': 342,\n",
              " '언': 343,\n",
              " '나플': 344,\n",
              " '듣고싶어': 345,\n",
              " '가슴': 346,\n",
              " '고등': 347,\n",
              " '래퍼': 348,\n",
              " '수란': 349,\n",
              " '좋더라': 350,\n",
              " '을': 351,\n",
              " '가사': 352,\n",
              " '즐거운': 353,\n",
              " '에이핑크': 354,\n",
              " '주세요': 355,\n",
              " '우': 356,\n",
              " '존경': 357,\n",
              " '바보': 358,\n",
              " '누나': 359,\n",
              " '토마토': 360,\n",
              " '감': 361,\n",
              " '바지': 362,\n",
              " '고장': 363,\n",
              " '가방': 364,\n",
              " '밥': 365,\n",
              " '일어': 366,\n",
              " '아랍어': 367,\n",
              " '러시아어': 368,\n",
              " '소식': 369,\n",
              " '나왔니': 370,\n",
              " '읽어줘': 371,\n",
              " '읽어줄래요': 372,\n",
              " '태권도': 373,\n",
              " '펜싱': 374,\n",
              " '손흥민': 375,\n",
              " '읽어줘요': 376,\n",
              " '재미': 377,\n",
              " '있는': 378,\n",
              " '해주겠니': 379,\n",
              " '날이니요': 380,\n",
              " '알고있나': 381,\n",
              " '였나': 382,\n",
              " '강릉': 383,\n",
              " '안산': 384,\n",
              " '영등포': 385,\n",
              " '보면': 386,\n",
              " '써야하니': 387,\n",
              " '글피': 388,\n",
              " '것': 389,\n",
              " '금천구': 390,\n",
              " '소크라테스': 391,\n",
              " '미래': 392,\n",
              " '김수경': 393,\n",
              " '유재석': 394,\n",
              " '해시': 395,\n",
              " '스완': 396,\n",
              " '베': 397,\n",
              " '이즈': 398,\n",
              " '한국': 399,\n",
              " 'UN': 400,\n",
              " '사무': 401,\n",
              " '총장': 402,\n",
              " '대체': 403,\n",
              " '알고싶어': 404,\n",
              " '챙길까': 405,\n",
              " '홍대': 406,\n",
              " '이런': 407,\n",
              " '먹을까요': 408,\n",
              " '정': 409,\n",
              " '맛있죠': 410,\n",
              " '송천동': 411,\n",
              " '익산': 412,\n",
              " '제주도': 413,\n",
              " '디지몬': 414,\n",
              " '포켓몬': 415,\n",
              " '서태지': 416,\n",
              " '걸스데이': 417,\n",
              " '루피': 418,\n",
              " '아이오': 419,\n",
              " '아이': 420,\n",
              " '노을': 421,\n",
              " '3': 422,\n",
              " '길': 423,\n",
              " '다시': 424,\n",
              " '밴드': 425,\n",
              " '장범준': 426,\n",
              " '영화': 427,\n",
              " '기억': 428,\n",
              " '빅뱅': 429,\n",
              " '그레이': 430,\n",
              " '슬프더라': 431,\n",
              " '하': 432,\n",
              " '비투비': 433,\n",
              " '행주': 434,\n",
              " '트로트': 435,\n",
              " '듣고싶네': 436,\n",
              " '온': 437,\n",
              " '영': 438,\n",
              " '들려': 439,\n",
              " '아이돌': 440,\n",
              " '양': 441,\n",
              " '요요': 442,\n",
              " '목성': 443,\n",
              " '죽을래': 444,\n",
              " '창문': 445,\n",
              " '상어': 446,\n",
              " '할머니': 447,\n",
              " '났어': 448,\n",
              " '귀하': 449,\n",
              " '코뿔소': 450,\n",
              " '당신': 451,\n",
              " '얼마': 452,\n",
              " '해왕성': 453,\n",
              " '정성': 454,\n",
              " '이다': 455,\n",
              " '밥솥': 456,\n",
              " '고치': 457,\n",
              " '칠판': 458,\n",
              " '미안해': 459,\n",
              " '오징어': 460,\n",
              " '게임': 461,\n",
              " '초밥': 462,\n",
              " '티비': 463,\n",
              " '불법': 464,\n",
              " '읽어': 465,\n",
              " '즐': 466,\n",
              " '연예': 467,\n",
              " '이건희': 468,\n",
              " '아시안': 469,\n",
              " '현대': 470,\n",
              " '조던': 471,\n",
              " '승리': 472,\n",
              " '일있니요': 473,\n",
              " '순위': 474,\n",
              " '박미선': 475,\n",
              " '더': 476,\n",
              " '인데': 477,\n",
              " '다다': 478,\n",
              " '음': 479,\n",
              " '보령': 480,\n",
              " '영월': 481,\n",
              " '쓰기': 482,\n",
              " '싫은데': 483,\n",
              " '있을까': 484,\n",
              " '있겠나요': 485,\n",
              " '좋을까요': 486,\n",
              " '실': 487,\n",
              " '흐릴까': 488,\n",
              " '흐려': 489,\n",
              " '꼈니': 490,\n",
              " '챙겨야': 491,\n",
              " '고민': 492,\n",
              " '순천': 493,\n",
              " '평택': 494,\n",
              " '부냐': 495,\n",
              " '흐리나요': 496,\n",
              " '흐려요': 497,\n",
              " '공주': 498,\n",
              " '고깃집': 499,\n",
              " '왕': 500,\n",
              " '성남': 501,\n",
              " '송파구': 502,\n",
              " '술집': 503,\n",
              " '떡볶이': 504,\n",
              " '여수': 505,\n",
              " '음료수': 506,\n",
              " '레인보우': 507,\n",
              " '조현영': 508,\n",
              " '가인': 509,\n",
              " '브라운': 510,\n",
              " '이드': 511,\n",
              " '걸스': 512,\n",
              " '달샤벳': 513,\n",
              " '도끼': 514,\n",
              " '김효': 515,\n",
              " '매드': 516,\n",
              " '클라': 517,\n",
              " '운': 518,\n",
              " '어반자카파': 519,\n",
              " '어반': 520,\n",
              " '자': 521,\n",
              " '카파': 522,\n",
              " '로보트': 523,\n",
              " '씨잼': 524,\n",
              " '베이식': 525,\n",
              " '슈퍼': 526,\n",
              " '면도': 527,\n",
              " '에듀': 528,\n",
              " '케이트': 529,\n",
              " '콜라보': 530,\n",
              " 'wu': 531,\n",
              " '투': 532,\n",
              " '원': 533,\n",
              " '지아': 534,\n",
              " 'mp': 535,\n",
              " '허각': 536,\n",
              " '윤도현': 537,\n",
              " '넬': 538,\n",
              " '아이비': 539,\n",
              " '들으려고': 540,\n",
              " '만난': 541,\n",
              " '세계': 542,\n",
              " '우울한데': 543,\n",
              " '들려줄': 544,\n",
              " '애': 545,\n",
              " '드시어': 546,\n",
              " '런': 547,\n",
              " '쉐이프': 548,\n",
              " '오브': 549,\n",
              " '미': 550,\n",
              " '혁오': 551,\n",
              " '감성': 552,\n",
              " '아픈': 553,\n",
              " '발라드': 554,\n",
              " '잭스': 555,\n",
              " '키스': 556,\n",
              " '아프지': 557,\n",
              " '마': 558,\n",
              " 'EDM': 559,\n",
              " '안나는데': 560,\n",
              " '이름': 561,\n",
              " '모르겠는데': 562,\n",
              " '마룬': 563,\n",
              " '파이브': 564,\n",
              " '트둥': 565,\n",
              " '다비치': 566,\n",
              " '원더걸스': 567,\n",
              " '추억': 568,\n",
              " '미스': 569,\n",
              " '에이': 570,\n",
              " '수지': 571,\n",
              " '포미닛': 572,\n",
              " '뱅뱅뱅': 573,\n",
              " '히트': 574,\n",
              " '곡': 575,\n",
              " '하기나': 576,\n",
              " '크러쉬': 577,\n",
              " '블루스': 578,\n",
              " '재즈': 579,\n",
              " '증인': 580,\n",
              " '클럽': 581,\n",
              " '나온다면': 582,\n",
              " '우디': 583,\n",
              " '윤종신': 584,\n",
              " '오아시스': 585,\n",
              " '김범수': 586,\n",
              " '좋겠네': 587,\n",
              " '샤이니': 588,\n",
              " '청': 589,\n",
              " 'winner': 590,\n",
              " '싶어져': 591,\n",
              " '현아': 592,\n",
              " '베베': 593,\n",
              " '취하': 594,\n",
              " '면': 595,\n",
              " '지코': 596,\n",
              " '동방신기': 597,\n",
              " '주문': 598,\n",
              " '미로틱': 599,\n",
              " '마이걸': 600,\n",
              " '보이비': 601,\n",
              " '이센스': 602,\n",
              " '구수한': 603,\n",
              " '틀어줄래': 604,\n",
              " '알앤비': 605,\n",
              " '소울': 606,\n",
              " '첸': 607,\n",
              " 'make': 608,\n",
              " 'it': 609,\n",
              " 'count': 610,\n",
              " '멜론': 611,\n",
              " '숀': 612,\n",
              " 'way': 613,\n",
              " 'back': 614,\n",
              " 'home': 615,\n",
              " 'ariana': 616,\n",
              " 'grande': 617,\n",
              " 'aoa': 618,\n",
              " '소년단': 619,\n",
              " '싶어': 620,\n",
              " '때': 621,\n",
              " '김하': 622,\n",
              " '인기가요': 623,\n",
              " '우울한': 624,\n",
              " '희망': 625,\n",
              " '비극': 626,\n",
              " '뜨거운': 627,\n",
              " '싶은데': 628,\n",
              " '주겠니': 629,\n",
              " '그룹': 630,\n",
              " '랩': 631,\n",
              " '창모': 632,\n",
              " '한요': 633,\n",
              " '기리보이': 634,\n",
              " '홍진영': 635,\n",
              " '틀어줄래요': 636,\n",
              " '틀어줘요': 637,\n",
              " '오션': 638,\n",
              " '다': 639,\n",
              " '원재': 640,\n",
              " '태양': 641,\n",
              " '좋': 642,\n",
              " '더세요': 643,\n",
              " '소설': 644,\n",
              " '문어': 645,\n",
              " '코끼리': 646,\n",
              " '바라볼래요': 647,\n",
              " '텅': 648,\n",
              " '비었군요': 649,\n",
              " '파이프': 650,\n",
              " '탱크': 651,\n",
              " '에어컨': 652,\n",
              " '칫솔': 653,\n",
              " '마우스': 654,\n",
              " '가나': 655,\n",
              " '설거지': 656,\n",
              " '해야': 657,\n",
              " '깨끗하군요': 658,\n",
              " '들어요': 659,\n",
              " '사나이': 660,\n",
              " '돼지': 661,\n",
              " '배': 662,\n",
              " '여자': 663,\n",
              " '바이올린': 664,\n",
              " '셔츠': 665,\n",
              " '간장': 666,\n",
              " '공기청정기': 667,\n",
              " '퇴장': 668,\n",
              " '모니터': 669,\n",
              " '군인': 670,\n",
              " '먹고싶어요': 671,\n",
              " '속보': 672,\n",
              " '나왔었니': 673,\n",
              " '살인': 674,\n",
              " '아이티': 675,\n",
              " '홈런': 676,\n",
              " '컵': 677,\n",
              " '엘에이': 678,\n",
              " '다저스': 679,\n",
              " '삼성': 680,\n",
              " '에스케이': 681,\n",
              " '금호': 682,\n",
              " '타이어': 683,\n",
              " '케이씨씨': 684,\n",
              " '유나이티드': 685,\n",
              " '맨체스터': 686,\n",
              " '플레이오프': 687,\n",
              " '감자': 688,\n",
              " '김지수': 689,\n",
              " '무당': 690,\n",
              " '눈사람': 691,\n",
              " '박지성': 692,\n",
              " '궁전': 693,\n",
              " '문자': 694,\n",
              " '정수': 695,\n",
              " '오미연': 696,\n",
              " '장사꾼': 697,\n",
              " '소리': 698,\n",
              " '꾼': 699,\n",
              " '암탉': 700,\n",
              " '수탉': 701,\n",
              " '국회': 702,\n",
              " '있니요': 703,\n",
              " '북한': 704,\n",
              " '안보리': 705,\n",
              " '정상': 706,\n",
              " '회담': 707,\n",
              " '있었니요': 708,\n",
              " '가두리': 709,\n",
              " '특보': 710,\n",
              " '특종': 711,\n",
              " '컴퓨터': 712,\n",
              " '코파': 713,\n",
              " '해주겠나요': 714,\n",
              " '날이죠': 715,\n",
              " '모르겠네': 716,\n",
              " '였지': 717,\n",
              " '알고싶어요': 718,\n",
              " '였더라': 719,\n",
              " '되더라': 720,\n",
              " '일일': 721,\n",
              " '까': 722,\n",
              " '어떤데': 723,\n",
              " '완산구': 724,\n",
              " '좋은가요': 725,\n",
              " '고령': 726,\n",
              " '나주': 727,\n",
              " '부안': 728,\n",
              " '서천': 729,\n",
              " '영덕': 730,\n",
              " '가로수길': 731,\n",
              " '권지용': 732,\n",
              " '김지원': 733,\n",
              " '백': 734,\n",
              " '김동주': 735,\n",
              " '박근혜': 736,\n",
              " '이병철': 737,\n",
              " '최': 738,\n",
              " '순': 739,\n",
              " '시라소니': 740,\n",
              " '알고있니': 741,\n",
              " '유병재': 742,\n",
              " '신': 743,\n",
              " '고요': 744,\n",
              " '알고있죠': 745,\n",
              " '문': 746,\n",
              " '세종': 747,\n",
              " '맑아': 748,\n",
              " '청주': 749,\n",
              " '춘천': 750,\n",
              " '동구': 751,\n",
              " '옷': 752,\n",
              " '입어야': 753,\n",
              " '서산': 754,\n",
              " '부는지': 755,\n",
              " '송도': 756,\n",
              " '이천': 757,\n",
              " '상주': 758,\n",
              " '오냐': 759,\n",
              " '부천': 760,\n",
              " '일산': 761,\n",
              " '있지': 762,\n",
              " '거기': 763,\n",
              " '있지요': 764,\n",
              " '먹을까': 765,\n",
              " '어떤거': 766,\n",
              " '먹을만': 767,\n",
              " '알려주세': 768,\n",
              " '어떤게': 769,\n",
              " '소문난': 770,\n",
              " '유성구': 771,\n",
              " '비빔밥': 772,\n",
              " '라멘': 773,\n",
              " '수원': 774,\n",
              " '유명한': 775,\n",
              " '김밥': 776,\n",
              " '아이스크림': 777,\n",
              " '빵집': 778,\n",
              " '순창': 779,\n",
              " '양주': 780,\n",
              " '닭꼬치': 781,\n",
              " '새우': 782,\n",
              " '튀김': 783,\n",
              " '수제': 784,\n",
              " '버거': 785,\n",
              " '쌀국수': 786,\n",
              " '맛있어요': 787,\n",
              " '스윙스': 788,\n",
              " '빅스': 789,\n",
              " '더콰이엇': 790,\n",
              " '플로우': 791,\n",
              " '보아': 792,\n",
              " 'Boa': 793,\n",
              " 'bgm': 794,\n",
              " '엑소': 795,\n",
              " '애넥도트': 796,\n",
              " '버벌진트': 797,\n",
              " '소녀시대': 798,\n",
              " '그렇게': 799,\n",
              " 'believer': 800,\n",
              " '알리': 801,\n",
              " '손승연': 802,\n",
              " 'emd': 803,\n",
              " '성시경': 804,\n",
              " '감미롭던데': 805,\n",
              " '버스커': 806,\n",
              " '효린': 807,\n",
              " '하하': 808,\n",
              " '빡센': 809,\n",
              " '외힙': 810,\n",
              " '살기': 811,\n",
              " '위해': 812,\n",
              " '서': 813,\n",
              " '베토벤': 814,\n",
              " '클래식': 815,\n",
              " '팝송': 816,\n",
              " '브리티쉬': 817,\n",
              " '들을려고': 818,\n",
              " '아플': 819,\n",
              " '들을만한': 820,\n",
              " '힘들': 821,\n",
              " '듣기': 822,\n",
              " '아이콘': 823,\n",
              " '했다': 824,\n",
              " '닐': 825,\n",
              " '지나오다': 826,\n",
              " '멜': 827,\n",
              " '로망스': 828,\n",
              " '별': 829,\n",
              " '빛나는': 830,\n",
              " '빈첸': 831,\n",
              " '하선': 832,\n",
              " '호': 833,\n",
              " '허클베리피': 834,\n",
              " '붕붕': 835,\n",
              " '바코드': 836,\n",
              " '기분': 837,\n",
              " '이은미': 838,\n",
              " '녹턴': 839,\n",
              " '동요': 840,\n",
              " '재밌는': 841,\n",
              " '들려줄수있니': 842,\n",
              " '잔잔한': 843,\n",
              " '뉴에이지': 844,\n",
              " '시원한': 845,\n",
              " '상쾌한': 846,\n",
              " '걷는': 847,\n",
              " '소나무': 848,\n",
              " '이수': 849,\n",
              " '들려줬으면': 850,\n",
              " '좋겠어': 851,\n",
              " '좋다': 852,\n",
              " '그루비': 853,\n",
              " '룸': 854,\n",
              " '프로': 855,\n",
              " '듀스': 856,\n",
              " '코드': 857,\n",
              " '쿤스트': 858,\n",
              " '자이언티': 859,\n",
              " '양화대교': 860,\n",
              " '베베미뇽': 861,\n",
              " '듣고싶은데': 862,\n",
              " '10': 863,\n",
              " 'cm': 864,\n",
              " '세븐': 865,\n",
              " '틴': 866,\n",
              " '왼': 867,\n",
              " '리쌍': 868,\n",
              " '아름다워': 869,\n",
              " '싶네요': 870,\n",
              " '라붐': 871,\n",
              " '노엘': 872,\n",
              " '헬리콥터': 873,\n",
              " '릴': 874,\n",
              " '보이': 875,\n",
              " '먼데이': 876,\n",
              " '키즈': 877,\n",
              " '가울': 878,\n",
              " '안부': 879,\n",
              " '백예린': 880,\n",
              " '신곡': 881,\n",
              " '나왔던데': 882,\n",
              " '엔플라잉': 883,\n",
              " '옥탑방': 884,\n",
              " '재키': 885,\n",
              " '검': 886,\n",
              " '최하': 887,\n",
              " '민': 888,\n",
              " '웨이브': 889,\n",
              " '송민호': 890,\n",
              " '아낙네': 891,\n",
              " '고백': 892,\n",
              " '들어줄래요': 893,\n",
              " '벤의': 894,\n",
              " '연애': 895,\n",
              " '중': 896,\n",
              " '선미': 897,\n",
              " '누': 898,\n",
              " '아르': 899,\n",
              " '호불호': 900,\n",
              " '시차': 901,\n",
              " 'exid': 902,\n",
              " '러블': 903,\n",
              " '리즈': 904,\n",
              " '여자친구': 905,\n",
              " '걸그룹': 906,\n",
              " '후예': 907,\n",
              " '줄래요': 908,\n",
              " '2': 909,\n",
              " 'ne': 910,\n",
              " '1': 911,\n",
              " '싶어져요': 912,\n",
              " '모모': 913,\n",
              " '랜드': 914,\n",
              " '애프터스쿨': 915,\n",
              " '우주소녀': 916,\n",
              " '아스트로': 917,\n",
              " '틀어주세': 918,\n",
              " '스나이퍼': 919,\n",
              " '로꼬': 920,\n",
              " '비스트': 921,\n",
              " '좋던데요': 922,\n",
              " '노라조': 923,\n",
              " '형': 924,\n",
              " '한동근': 925,\n",
              " '끝': 926,\n",
              " '써': 927,\n",
              " '보려해': 928,\n",
              " '박진영': 929,\n",
              " '허니': 930,\n",
              " '트와이스': 931,\n",
              " '이쁘다': 932,\n",
              " '방탄소년단': 933,\n",
              " '멋있어': 934,\n",
              " '소고기': 935,\n",
              " '할아버지': 936,\n",
              " '토끼': 937,\n",
              " '호전': 938,\n",
              " '장갑': 939,\n",
              " '기차': 940,\n",
              " '청소기': 941,\n",
              " '명치': 942,\n",
              " '로마': 943,\n",
              " '상장': 944,\n",
              " '책상': 945,\n",
              " '박사': 946,\n",
              " '상기': 947,\n",
              " '멸치': 948,\n",
              " '리모컨': 949,\n",
              " '장치': 950,\n",
              " '수기': 951,\n",
              " '경찰': 952,\n",
              " '훼방': 953,\n",
              " '영국': 954,\n",
              " '지구': 955,\n",
              " '가위': 956,\n",
              " '동전': 957,\n",
              " '등산': 958,\n",
              " '남자': 959,\n",
              " '사과': 960,\n",
              " '이불': 961,\n",
              " '해파리': 962,\n",
              " '동생': 963,\n",
              " '기타': 964,\n",
              " '자전거': 965,\n",
              " '토성': 966,\n",
              " '고마워': 967,\n",
              " '등장': 968,\n",
              " '방문': 969,\n",
              " '파인애플': 970,\n",
              " '전기': 971,\n",
              " '물고기': 972,\n",
              " '배고파요': 973,\n",
              " '배고파서': 974,\n",
              " '잠': 975,\n",
              " '안오네요': 976,\n",
              " '가고싶어요': 977,\n",
              " '시장': 978,\n",
              " '왔어요': 979,\n",
              " '입어': 980,\n",
              " '야해요': 981,\n",
              " '침대': 982,\n",
              " '누워': 983,\n",
              " '수납': 984,\n",
              " '장': 985,\n",
              " '진심': 986,\n",
              " '으로': 987,\n",
              " '서랍': 988,\n",
              " '의자': 989,\n",
              " '소방관': 990,\n",
              " '읽어줄래': 991,\n",
              " '나왔던': 992,\n",
              " '뭐라고': 993,\n",
              " '했니': 994,\n",
              " '일있니': 995,\n",
              " '오지헌': 996,\n",
              " '헌': 997,\n",
              " '박명수': 998,\n",
              " '추사': 999,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RaY-kIL_xfX"
      },
      "source": [
        "# 3. data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsEwL9R1_xfY"
      },
      "source": [
        "label_to_id = {t:i for i,t in enumerate(df.intent.unique())}\n",
        "id_to_label = {i:t for i,t in enumerate(df.intent.unique())}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufJse9NB_xfY",
        "outputId": "aaac8a56-a931-489b-d047-a78de8eb9600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(label_to_id)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'음악': 0, '번역': 1, '뉴스': 2, '명언': 3, '달력': 4, '먼지': 5, '인물': 6, '시간': 7, '이슈': 8, '날씨': 9, '맛집': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqcA3I_9_xfY"
      },
      "source": [
        "# df.intent = df.intent.map(lambda x : label_index[x])\n",
        "# print(df.head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emAGfx7-_xfZ"
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "def tokenize_and_filter(sentences, labels):\n",
        "  inputs, outputs = [], []\n",
        "  \n",
        "  for sentence, label in zip(sentences, labels):\n",
        "    # tokenize sentence\n",
        "    tokenized_sentence = tokenizer.encode_a_doc_to_list(sentence)\n",
        "    # check tokenized sentence max length\n",
        "    if len(tokenized_sentence) <= MAX_LENGTH:\n",
        "      inputs.append(tokenized_sentence)\n",
        "      outputs.append(label_to_id[label])\n",
        "  \n",
        "  # pad tokenized sentences\n",
        "  padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      inputs, maxlen=MAX_LENGTH, padding='post', \n",
        "      value = tokenizer.vocabulary_['_PAD_']) # value = 0\n",
        "  \n",
        "  return padded_inputs, outputs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV47YqOW_xfa"
      },
      "source": [
        "inputs, outputs = tokenize_and_filter(df.question, df.intent)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP5XQp-d_xfa",
        "outputId": "b2c85588-7443-42c7-b3c5-b8abef38007f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('encoded input : ', inputs[0], 'label : ', outputs[0], 'original input sentence : ', tokenizer.decode_from_list(inputs[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded input :  [185  73  19   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0] label :  0 original input sentence :  ['에픽하이', '우산', '들려줘', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_', '_PAD_']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agJ6trdu_xfb"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 7836\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
        "dataset = dataset.shuffle(3000, reshuffle_each_iteration=False)\n",
        "val_ds = dataset.take(500)\n",
        "train_ds = dataset.skip(500)\n",
        "\n",
        "def configure_ds(dataset):\n",
        "  dataset = dataset.cache()\n",
        "  dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return dataset\n",
        "train_ds = configure_ds(train_ds)\n",
        "val_ds = configure_ds(val_ds)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xEQl9P_c_xfc",
        "outputId": "ba52fdde-d561-4e51-91f2-f71bc2a1674c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for x, y in train_ds.take(1):\n",
        "    print(x, y)\n",
        "    print('-----------------------------------------------')\n",
        "    print(x.shape, y.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[  90   87  146   21   13    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  42   25   19    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  27   11   10   97    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [1181    7    8    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  60   39   23    9    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [ 199  210   99   85    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [ 152   28   61  101    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  14    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [ 326   32  504  147   17   95    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [ 149  224   78   31    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   4   10  109    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [ 519   16   19    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  12   60   39   42    9    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   4   25  155   36   31    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  12   25  119  262    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [ 947  170   46    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0]], shape=(16, 40), dtype=int32) tf.Tensor([ 1  2  9  6  8 10 10  7 10  2  9  0  8  4  8  1], shape=(16,), dtype=int32)\n",
            "-----------------------------------------------\n",
            "(16, 40) (16,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM-jbs6U_xfc"
      },
      "source": [
        "# 4. model design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stTwC73u_xfd",
        "outputId": "6999092a-7a99-4b9d-bb5e-fbb3765faae5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(label_to_id.values()))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_1oMbSL_xfd"
      },
      "source": [
        "def get_model():\n",
        "    return tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(tokenizer.n_vocabs, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(label_to_id.values()), activation='softmax')\n",
        "])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj7zsReW_xfe"
      },
      "source": [
        "model = get_model()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTGqJJ_-_xfe"
      },
      "source": [
        "LEARNING_RATE = 0.0001"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTHLXxDT_xff"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPFfbe81EJaU",
        "outputId": "05b27b74-9bf3-4989-aa15-7b8c4365edab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, j in train_ds.take(1):\n",
        "  print(i.shape, j)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 40) tf.Tensor([ 0  7  9  4  3  8  6  9  7 10  4  8  3  5  6  0], shape=(16,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43P6DrB__xff",
        "outputId": "4ccdffb1-ba87-4754-e787-f1eed4649ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "194/194 [==============================] - 7s 14ms/step - loss: 2.3829 - sparse_categorical_accuracy: 0.1495 - val_loss: 2.3736 - val_sparse_categorical_accuracy: 0.1780\n",
            "Epoch 2/10\n",
            "194/194 [==============================] - 2s 9ms/step - loss: 2.3048 - sparse_categorical_accuracy: 0.2863 - val_loss: 2.1883 - val_sparse_categorical_accuracy: 0.4400\n",
            "Epoch 3/10\n",
            "194/194 [==============================] - 2s 9ms/step - loss: 1.8855 - sparse_categorical_accuracy: 0.5205 - val_loss: 1.6386 - val_sparse_categorical_accuracy: 0.4800\n",
            "Epoch 4/10\n",
            "194/194 [==============================] - 2s 9ms/step - loss: 1.3501 - sparse_categorical_accuracy: 0.7189 - val_loss: 1.1783 - val_sparse_categorical_accuracy: 0.7800\n",
            "Epoch 5/10\n",
            "194/194 [==============================] - 2s 9ms/step - loss: 0.9515 - sparse_categorical_accuracy: 0.8447 - val_loss: 0.9054 - val_sparse_categorical_accuracy: 0.8700\n",
            "Epoch 6/10\n",
            "194/194 [==============================] - 2s 9ms/step - loss: 0.6896 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.9200\n",
            "Epoch 7/10\n",
            "194/194 [==============================] - 2s 9ms/step - loss: 0.5067 - sparse_categorical_accuracy: 0.9418 - val_loss: 0.4847 - val_sparse_categorical_accuracy: 0.9500\n",
            "Epoch 8/10\n",
            "194/194 [==============================] - 2s 9ms/step - loss: 0.3798 - sparse_categorical_accuracy: 0.9573 - val_loss: 0.4123 - val_sparse_categorical_accuracy: 0.9440\n",
            "Epoch 9/10\n",
            "194/194 [==============================] - 2s 8ms/step - loss: 0.2915 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.2961 - val_sparse_categorical_accuracy: 0.9660\n",
            "Epoch 10/10\n",
            "194/194 [==============================] - 2s 9ms/step - loss: 0.2265 - sparse_categorical_accuracy: 0.9741 - val_loss: 0.2428 - val_sparse_categorical_accuracy: 0.9720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fab2e134790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvUyT88v_xfg"
      },
      "source": [
        "def question_processing(sentences):\n",
        "    inputs = []\n",
        "    for sentence in sentences:\n",
        "        # tokenize sentence\n",
        "        tokenized_sentence = tokenizer.encode_a_doc_to_list(sentence)\n",
        "        # check tokenized sentence max length\n",
        "        if len(tokenized_sentence) <= MAX_LENGTH:\n",
        "            inputs.append(tokenized_sentence)\n",
        "        else:\n",
        "            print('입력이 너무 길어요.')\n",
        "    # pad tokenized sentences\n",
        "    padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    inputs, maxlen=MAX_LENGTH, padding='post', \n",
        "    value = tokenizer.vocabulary_['_PAD_']) # value = 0\n",
        "    return padded_inputs"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5IRG-OJFh-d",
        "outputId": "c58fa895-5fa6-412d-a72e-d0b299960764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "question_processing([\"나는 전주 날씨 궁금함\"])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 30, 130, 135,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xwnyLs2_xfh"
      },
      "source": [
        "input_sentence = question_processing(['서울 날씨 어때?', \n",
        "                                      '나는 전주 날씨 궁금함',\n",
        "                                      '안중근 의사는 누구야?',\n",
        "                                      '이순신 장군은 어떤 분이니?',\n",
        "                                      '명동 맛있는 음식점 있니?'\n",
        "                                     ])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKu5rRiP_xfj",
        "outputId": "992f5c8e-5fbd-4d03-a0e5-90291da9055e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.predict(input_sentence)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.34740989e-02, 6.15719819e-06, 1.22649437e-02, 2.12770331e-07,\n",
              "        1.89632282e-03, 4.59708885e-04, 8.76961130e-05, 1.77765619e-02,\n",
              "        2.87766289e-03, 9.16435838e-01, 1.47208460e-02],\n",
              "       [6.98929280e-02, 5.27820202e-06, 1.07014002e-02, 1.43738885e-06,\n",
              "        8.29131901e-03, 6.28543377e-04, 1.49984407e-04, 4.77604792e-02,\n",
              "        9.08961147e-03, 8.38718295e-01, 1.47606730e-02],\n",
              "       [1.49378367e-02, 2.03916095e-02, 9.69733286e-04, 4.43652049e-02,\n",
              "        5.52695524e-03, 1.85251562e-03, 8.79908085e-01, 9.75205476e-05,\n",
              "        2.23294563e-07, 7.57845934e-04, 3.11925020e-02],\n",
              "       [1.50376901e-01, 2.01502335e-05, 5.75422775e-03, 5.94119156e-05,\n",
              "        1.06199585e-01, 1.39980786e-03, 1.38088898e-03, 5.30403256e-01,\n",
              "        1.01618953e-02, 1.59425795e-01, 3.48181315e-02],\n",
              "       [1.31182894e-01, 3.84239502e-05, 1.79505395e-03, 1.37859810e-04,\n",
              "        2.35977233e-03, 1.39308177e-04, 1.52279474e-02, 3.27018239e-02,\n",
              "        2.09725622e-05, 3.30121890e-02, 7.83383727e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTVpCK7D_xfj",
        "outputId": "aeee698e-4f69-4672-8696-ac472a87b50f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prediction = np.argmax(model.predict(input_sentence), axis=1)\n",
        "print(prediction)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 9  9  6  7 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU_UOA2n_xfk",
        "outputId": "35518012-954d-45a2-bfff-9ebd30e5dcdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for p in prediction:\n",
        "    print(id_to_label[p])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "날씨\n",
            "날씨\n",
            "인물\n",
            "시간\n",
            "맛집\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAa9A4x2_xfk"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONSsJmI1_xfk"
      },
      "source": [
        "# 데이터 추가해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvw3JHDm_xfl"
      },
      "source": [
        "names = ['안중근', '이순신', '세종대왕', '김광석', '아이유', '에미넴', '이건희', '고아라', '유재석', '한석희', '최민성']\n",
        "def question_generator(names):\n",
        "    question = []\n",
        "    for name in names:\n",
        "        s1 = name+'는 어떤 분이야?'\n",
        "        s2 = name+'은 어떤 사람이니?'\n",
        "        s3 = name+'이란 사람에 대해 궁금해'\n",
        "        question = question+[s1, s2, s3]\n",
        "    return question\n",
        "question = question_generator(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj1qWVhA_xfl"
      },
      "source": [
        "question"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VpIQNst_xfl"
      },
      "source": [
        "new_data = {'question' : question, 'intent' : ['인물']*len(question)}\n",
        "add_df = pd.DataFrame(new_data, columns=('question', 'intent'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y10ZT0Ai_xfm"
      },
      "source": [
        "add_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaalL8Ln_xfm"
      },
      "source": [
        "print(len(df), len(add_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kcy6R8h_xfm"
      },
      "source": [
        "new_df = pd.concat([df, add_df])\n",
        "print(len(new_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDQ7l4by_xfn"
      },
      "source": [
        "tokenizer.fit(new_df['question'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHHqOYPM_xfn"
      },
      "source": [
        "new_inputs, new_outputs = tokenize_and_filter(new_df.question, new_df.intent)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 7836\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((new_inputs, new_outputs))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiYVOPc5_xfo"
      },
      "source": [
        "new_model = get_model()\n",
        "LEARNING_RATE = 0.0001\n",
        "new_model.compile(optimizer=tf.keras.optimizers.Adam(LEARNING_RATE),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "new_model.fit(dataset, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J88KUxZs_xfo"
      },
      "source": [
        "input_sentence = question_processing(['서울 날씨 어때?', \n",
        "                                      '나는 전주 날씨 궁금함',\n",
        "                                      '안중근 의사는 누구야?',\n",
        "                                      '박소희는 어떤 사람인지 궁금해.',\n",
        "                                      '명동 맛있는 음식점 있니?'\n",
        "                                     ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wyDdvy__xfp"
      },
      "source": [
        "new_model.predict(input_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYQnW7Bo_xfp"
      },
      "source": [
        "prediction = np.argmax(new_model.predict(input_sentence), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61tc3Sk_xfq"
      },
      "source": [
        "for p in prediction:\n",
        "    print(id_to_label[p])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fDrKGu__xfr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}